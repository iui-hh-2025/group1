<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="author" content="Morgan Williams, Saima  Kalliola, Megan Elsen, Aline Diaz Williamson, Ilja Ylikangas"> 
	<meta name="description" content="Information about music AI and music recommendations created by AI">
	<meta name="keywords" content="artificial intelligence, AI, music, music recommendations, Spotify, YouTube Music, Apple Music">
	<link href="../style.css" rel="stylesheet" type="text/css"> 
	<title>AI, Music Recommendations, and You</title>
</head>

<body>
	<header>Future of Recommendations</header>
	
	<nav>
	<ul>
		<li><a href="../index.html">Home</a></li>
		<li><a href="historyofrecs.html">History of Recommendations</a></li>
		<li><a href="aimusicevolution.html">Evolution and Present</a></li>
		<li><a href="spotify.html">Spotify</a></li>
		<li><a href="youtubemusic.html">YouTube Music</a></li>
		<li><a href="applemusic.html">Apple Music</a></li>
		<li><a href="futureofrecs.html">Future of Recommendations</a></li>
	</ul>
	</nav>
	
	<aside>
		
	</aside>
	
	<main>
		<p>How will AI change how music is listened to in the future? [Continue intro text. pulling from new kinds of data, out of both desire for innovation and (in some cases) necessity]</p>

		<p>[Reference studies- looking at facial expressions, recommendations based on emotion. Currently in the hypothetical but studies are already laying the groundwork]</p>

		<p>[Other issue on horizon- consolidation of music vendors using proprietary datasets. Data walled off limits possibilities for innovation outside megacorps, but also leads to new approaches. Reference AMRM and its focus on small datasets]</p>

		<p>[Overall- foresee potential leaps in innnovation using the smallest human cues, but those leaps can easily be bottlenecked by need for large datasets that are almost entirely siloed by the big players]</p>
	</main>
	
	<footer>Website created by Group 1 for S531 &copy; 2025</footer>

</body>
</html>
